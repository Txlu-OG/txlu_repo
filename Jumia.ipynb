{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2f8dd14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraped page 1\n",
      "Scraped page 2\n",
      "Scraped page 3\n",
      "Scraped page 4\n",
      "Scraped page 5\n",
      "Scraped page 6\n",
      "Scraped page 7\n",
      "Scraped page 8\n",
      "Scraped page 9\n",
      "Scraped page 10\n",
      "Scraping completed and saved to 'nairaland_comments.csv'\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Set up Selenium WebDriver\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('--headless')\n",
    "driver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()), options=options)\n",
    "\n",
    "# Function to extract comments from a Nairaland thread page\n",
    "def extract_comments(url):\n",
    "    driver.get(url)\n",
    "    time.sleep(5)  # Wait for the page to load completely\n",
    "\n",
    "    comments = []\n",
    "    try:\n",
    "        comment_sections = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_all_elements_located((By.CLASS_NAME, 'narrow'))\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Error waiting for comment sections: {e}\")\n",
    "        return comments\n",
    "\n",
    "    for comment_div in comment_sections:\n",
    "        try:\n",
    "            comment_text = comment_div.text.strip()\n",
    "            comments.append({'text': comment_text})\n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting comment: {e}\")\n",
    "\n",
    "    return comments\n",
    "\n",
    "# Function to navigate through multiple pages of the thread\n",
    "def scrape_all_comments(base_url, start_page=1, end_page=10):\n",
    "    all_comments = []\n",
    "    for page_num in range(start_page, end_page + 1):\n",
    "        url = f\"{base_url}/{page_num}\"\n",
    "        comments = extract_comments(url)\n",
    "        all_comments.extend(comments)\n",
    "        print(f\"Scraped page {page_num}\")\n",
    "    \n",
    "    return all_comments\n",
    "\n",
    "# Example usage\n",
    "base_url = 'https://www.nairaland.com/1546964/konga-jumia-which-more-reliable'  # Provided thread base URL\n",
    "start_page = 1  # Starting page number\n",
    "end_page = 10  # Ending page number, adjust based on the total number of pages in the thread\n",
    "\n",
    "all_comments = scrape_all_comments(base_url, start_page, end_page)\n",
    "if all_comments:\n",
    "    comments_df = pd.DataFrame(all_comments)\n",
    "    comments_df.to_csv('nairaland_comments.csv', index=False)\n",
    "    print(\"Scraping completed and saved to 'nairaland_comments.csv'\")\n",
    "else:\n",
    "    print(\"No comments found.\")\n",
    "\n",
    "# Close the WebDriver\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64dc66f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
