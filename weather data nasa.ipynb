{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa99040b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for 5.4527, 7.5248 on 2018-01-01: 401\n",
      "Error fetching data for 5.4527, 7.5248 on 2018-01-02: 401\n",
      "Error fetching data for 5.4527, 7.5248 on 2018-01-03: 401\n",
      "Error fetching data for 5.4527, 7.5248 on 2018-01-04: 401\n",
      "Error fetching data for 5.4527, 7.5248 on 2018-01-05: 401\n",
      "Error fetching data for 5.4527, 7.5248 on 2018-01-06: 401\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 104\u001b[0m\n\u001b[1;32m     96\u001b[0m                     writer\u001b[38;5;241m.\u001b[39mwriterow({\n\u001b[1;32m     97\u001b[0m                         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstate\u001b[39m\u001b[38;5;124m'\u001b[39m: state,\n\u001b[1;32m     98\u001b[0m                         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m: datetime\u001b[38;5;241m.\u001b[39mutcfromtimestamp(hourly_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdt\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    101\u001b[0m                         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweather_description\u001b[39m\u001b[38;5;124m'\u001b[39m: hourly_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweather\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdescription\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    102\u001b[0m                     })\n\u001b[1;32m    103\u001b[0m             \u001b[38;5;66;03m# To avoid exceeding API rate limits, sleep between requests\u001b[39;00m\n\u001b[0;32m--> 104\u001b[0m             time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Adjust the sleep interval based on your API usage plan\u001b[39;00m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWeather data saved to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import csv\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# API Key\n",
    "API_KEY = '680094fa102be4bfda616a0856697a20'\n",
    "\n",
    "# Nigerian States with their coordinates\n",
    "nigerian_states_coords = {\n",
    "    'Abia': {'lat': 5.4527, 'lon': 7.5248},\n",
    "    'Adamawa': {'lat': 9.3265, 'lon': 12.3984},\n",
    "    'Akwa Ibom': {'lat': 5.0370, 'lon': 7.9128},\n",
    "    'Anambra': {'lat': 6.2209, 'lon': 7.0676},\n",
    "    'Bauchi': {'lat': 10.3157, 'lon': 9.8442},\n",
    "    'Bayelsa': {'lat': 4.7719, 'lon': 6.0699},\n",
    "    'Benue': {'lat': 7.3369, 'lon': 8.7404},\n",
    "    'Borno': {'lat': 11.8333, 'lon': 13.1500},\n",
    "    'Cross River': {'lat': 5.9631, 'lon': 8.5367},\n",
    "    'Delta': {'lat': 5.8904, 'lon': 5.6800},\n",
    "    'Ebonyi': {'lat': 6.2649, 'lon': 8.0130},\n",
    "    'Edo': {'lat': 6.5244, 'lon': 5.5197},\n",
    "    'Ekiti': {'lat': 7.6233, 'lon': 5.2190},\n",
    "    'Enugu': {'lat': 6.5244, 'lon': 7.5176},\n",
    "    'Gombe': {'lat': 10.2900, 'lon': 11.1700},\n",
    "    'Imo': {'lat': 5.5720, 'lon': 7.0588},\n",
    "    'Jigawa': {'lat': 12.1356, 'lon': 9.9285},\n",
    "    'Kaduna': {'lat': 10.5105, 'lon': 7.4165},\n",
    "    'Kano': {'lat': 12.0022, 'lon': 8.5919},\n",
    "    'Katsina': {'lat': 12.9908, 'lon': 7.5970},\n",
    "    'Kebbi': {'lat': 12.4500, 'lon': 4.1994},\n",
    "    'Kogi': {'lat': 7.7969, 'lon': 6.7333},\n",
    "    'Kwara': {'lat': 8.9669, 'lon': 4.5624},\n",
    "    'Lagos': {'lat': 6.5244, 'lon': 3.3792},\n",
    "    'Nasarawa': {'lat': 8.5373, 'lon': 8.2000},\n",
    "    'Niger': {'lat': 9.0810, 'lon': 6.5212},\n",
    "    'Ogun': {'lat': 7.1609, 'lon': 3.3466},\n",
    "    'Ondo': {'lat': 7.2507, 'lon': 5.1931},\n",
    "    'Osun': {'lat': 7.5628, 'lon': 4.5192},\n",
    "    'Oyo': {'lat': 7.9467, 'lon': 3.4820},\n",
    "    'Plateau': {'lat': 9.2182, 'lon': 9.5175},\n",
    "    'Rivers': {'lat': 4.8156, 'lon': 7.0498},\n",
    "    'Sokoto': {'lat': 13.0059, 'lon': 5.2476},\n",
    "    'Taraba': {'lat': 8.8937, 'lon': 11.3598},\n",
    "    'Yobe': {'lat': 12.0015, 'lon': 11.5000},\n",
    "    'Zamfara': {'lat': 12.1717, 'lon': 6.6614}\n",
    "}\n",
    "\n",
    "# Function to convert date to Unix timestamp\n",
    "def convert_to_timestamp(date_str):\n",
    "    dt = datetime.strptime(date_str, '%Y-%m-%d')\n",
    "    return int(time.mktime(dt.timetuple()))\n",
    "\n",
    "# Fetch weather data for a specific date and location\n",
    "def fetch_weather_data(lat, lon, date):\n",
    "    timestamp = convert_to_timestamp(date)\n",
    "    url = f\"http://api.openweathermap.org/data/2.5/onecall/timemachine?lat={lat}&lon={lon}&dt={timestamp}&appid={API_KEY}&units=metric\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(f\"Error fetching data for {lat}, {lon} on {date}: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "# Generate list of all dates from 2018-01-01 to 2022-12-31\n",
    "def generate_dates(start_date, end_date):\n",
    "    current_date = datetime.strptime(start_date, '%Y-%m-%d')\n",
    "    end_date = datetime.strptime(end_date, '%Y-%m-%d')\n",
    "    date_list = []\n",
    "    while current_date <= end_date:\n",
    "        date_list.append(current_date.strftime('%Y-%m-%d'))\n",
    "        current_date += timedelta(days=1)\n",
    "    return date_list\n",
    "\n",
    "# List of all dates from 2018 to 2022\n",
    "all_dates = generate_dates('2018-01-01', '2022-12-31')\n",
    "\n",
    "# File to save the weather data\n",
    "output_file = 'nigeria_weather_data_2018_2022.csv'\n",
    "\n",
    "# Open CSV file to write weather data\n",
    "with open(output_file, 'w', newline='') as csvfile:\n",
    "    fieldnames = ['state', 'date', 'temperature', 'humidity', 'weather_description']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "\n",
    "    # Fetch data for each state and each date\n",
    "    for state, coords in nigerian_states_coords.items():\n",
    "        lat = coords['lat']\n",
    "        lon = coords['lon']\n",
    "        for date in all_dates:\n",
    "            weather_data = fetch_weather_data(lat, lon, date)\n",
    "            if weather_data:\n",
    "                # Extract the necessary data\n",
    "                for hourly_data in weather_data['hourly']:\n",
    "                    writer.writerow({\n",
    "                        'state': state,\n",
    "                        'date': datetime.utcfromtimestamp(hourly_data['dt']).strftime('%Y-%m-%d %H:%M:%S'),\n",
    "                        'temperature': hourly_data['temp'],\n",
    "                        'humidity': hourly_data['humidity'],\n",
    "                        'weather_description': hourly_data['weather'][0]['description']\n",
    "                    })\n",
    "            # To avoid exceeding API rate limits, sleep between requests\n",
    "            time.sleep(1)  # Adjust the sleep interval based on your API usage plan\n",
    "\n",
    "print(f\"Weather data saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "face0616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key works! Here's the data: {'coord': {'lon': 3.75, 'lat': 6.5833}, 'weather': [{'id': 803, 'main': 'Clouds', 'description': 'broken clouds', 'icon': '04d'}], 'base': 'stations', 'main': {'temp': 301.33, 'feels_like': 304.6, 'temp_min': 301.33, 'temp_max': 301.33, 'pressure': 1011, 'humidity': 73, 'sea_level': 1011, 'grnd_level': 1011}, 'visibility': 10000, 'wind': {'speed': 4.33, 'deg': 222, 'gust': 6.48}, 'clouds': {'all': 82}, 'dt': 1726154182, 'sys': {'type': 1, 'id': 1185, 'country': 'NG', 'sunrise': 1726119367, 'sunset': 1726163192}, 'timezone': 3600, 'id': 2332453, 'name': 'Lagos', 'cod': 200}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "API_KEY = '680094fa102be4bfda616a0856697a20'\n",
    "city = 'Lagos'\n",
    "url = f\"http://api.openweathermap.org/data/2.5/weather?q={city}&appid={API_KEY}\"\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    print(\"API key works! Here's the data:\", response.json())\n",
    "else:\n",
    "    print(f\"Error: {response.status_code}, {response.text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2282041e",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'PRECTOT'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 78\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m weather_data \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproperties\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m weather_data:\n\u001b[1;32m     73\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m date, values \u001b[38;5;129;01min\u001b[39;00m weather_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproperties\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparameter\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mT2M\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     74\u001b[0m                 writer\u001b[38;5;241m.\u001b[39mwriterow({\n\u001b[1;32m     75\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstate\u001b[39m\u001b[38;5;124m'\u001b[39m: state,\n\u001b[1;32m     76\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m: date,\n\u001b[1;32m     77\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m'\u001b[39m: values,\n\u001b[0;32m---> 78\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprecipitation\u001b[39m\u001b[38;5;124m'\u001b[39m: weather_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproperties\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparameter\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPRECTOT\u001b[39m\u001b[38;5;124m'\u001b[39m][date]\n\u001b[1;32m     79\u001b[0m                 })\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWeather data saved to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'PRECTOT'"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import csv\n",
    "\n",
    "# NASA POWER API endpoint for daily data\n",
    "def get_nasa_power_data(lat, lon, start_date, end_date):\n",
    "    url = f\"https://power.larc.nasa.gov/api/temporal/daily/point?start={start_date}&end={end_date}&latitude={lat}&longitude={lon}&community=RE&parameters=T2M,PRECTOT&format=JSON\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(f\"Error fetching data for {lat}, {lon}: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "# Coordinates for Nigerian states\n",
    "nigerian_states_coords = {\n",
    "    'Abia': {'lat': 5.4527, 'lon': 7.5248},\n",
    "    'Adamawa': {'lat': 9.3265, 'lon': 12.3984},\n",
    "    'Akwa Ibom': {'lat': 5.0370, 'lon': 7.9128},\n",
    "    'Anambra': {'lat': 6.2209, 'lon': 7.0676},\n",
    "    'Bauchi': {'lat': 10.3157, 'lon': 9.8442},\n",
    "    'Bayelsa': {'lat': 4.7719, 'lon': 6.0699},\n",
    "    'Benue': {'lat': 7.3369, 'lon': 8.7404},\n",
    "    'Borno': {'lat': 11.8333, 'lon': 13.1500},\n",
    "    'Cross River': {'lat': 5.9631, 'lon': 8.5367},\n",
    "    'Delta': {'lat': 5.8904, 'lon': 5.6800},\n",
    "    'Ebonyi': {'lat': 6.2649, 'lon': 8.0130},\n",
    "    'Edo': {'lat': 6.5244, 'lon': 5.5197},\n",
    "    'Ekiti': {'lat': 7.6233, 'lon': 5.2190},\n",
    "    'Enugu': {'lat': 6.5244, 'lon': 7.5176},\n",
    "    'Gombe': {'lat': 10.2900, 'lon': 11.1700},\n",
    "    'Imo': {'lat': 5.5720, 'lon': 7.0588},\n",
    "    'Jigawa': {'lat': 12.1356, 'lon': 9.9285},\n",
    "    'Kaduna': {'lat': 10.5105, 'lon': 7.4165},\n",
    "    'Kano': {'lat': 12.0022, 'lon': 8.5919},\n",
    "    'Katsina': {'lat': 12.9908, 'lon': 7.5970},\n",
    "    'Kebbi': {'lat': 12.4500, 'lon': 4.1994},\n",
    "    'Kogi': {'lat': 7.7969, 'lon': 6.7333},\n",
    "    'Kwara': {'lat': 8.9669, 'lon': 4.5624},\n",
    "    'Lagos': {'lat': 6.5244, 'lon': 3.3792},\n",
    "    'Nasarawa': {'lat': 8.5373, 'lon': 8.2000},\n",
    "    'Niger': {'lat': 9.0810, 'lon': 6.5212},\n",
    "    'Ogun': {'lat': 7.1609, 'lon': 3.3466},\n",
    "    'Ondo': {'lat': 7.2507, 'lon': 5.1931},\n",
    "    'Osun': {'lat': 7.5628, 'lon': 4.5192},\n",
    "    'Oyo': {'lat': 7.9467, 'lon': 3.4820},\n",
    "    'Plateau': {'lat': 9.2182, 'lon': 9.5175},\n",
    "    'Rivers': {'lat': 4.8156, 'lon': 7.0498},\n",
    "    'Sokoto': {'lat': 13.0059, 'lon': 5.2476},\n",
    "    'Taraba': {'lat': 8.8937, 'lon': 11.3598},\n",
    "    'Yobe': {'lat': 12.0015, 'lon': 11.5000},\n",
    "    'Zamfara': {'lat': 12.1717, 'lon': 6.6614}\n",
    "}\n",
    "\n",
    "# Dates for fetching data\n",
    "start_date = \"20180101\"\n",
    "end_date = \"20221231\"\n",
    "\n",
    "# File to save weather data\n",
    "output_file = 'nasa_power_weather_data.csv'\n",
    "\n",
    "# Open CSV file and write headers\n",
    "with open(output_file, 'w', newline='') as csvfile:\n",
    "    fieldnames = ['state', 'date', 'temperature', 'precipitation']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "\n",
    "    # Fetch data for each state\n",
    "    for state, coords in nigerian_states_coords.items():\n",
    "        lat = coords['lat']\n",
    "        lon = coords['lon']\n",
    "        weather_data = get_nasa_power_data(lat, lon, start_date, end_date)\n",
    "        if weather_data and 'properties' in weather_data:\n",
    "            for date, values in weather_data['properties']['parameter']['T2M'].items():\n",
    "                writer.writerow({\n",
    "                    'state': state,\n",
    "                    'date': date,\n",
    "                    'temperature': values,\n",
    "                    'precipitation': weather_data['properties']['parameter']['PRECTOT'][date]\n",
    "                })\n",
    "\n",
    "print(f\"Weather data saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ad948cb",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'PRECTOT'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 78\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m weather_data \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproperties\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m weather_data:\n\u001b[1;32m     73\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m date, values \u001b[38;5;129;01min\u001b[39;00m weather_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproperties\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparameter\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mT2M\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     74\u001b[0m                 writer\u001b[38;5;241m.\u001b[39mwriterow({\n\u001b[1;32m     75\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstate\u001b[39m\u001b[38;5;124m'\u001b[39m: state,\n\u001b[1;32m     76\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m: date,\n\u001b[1;32m     77\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m'\u001b[39m: values,\n\u001b[0;32m---> 78\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprecipitation\u001b[39m\u001b[38;5;124m'\u001b[39m: weather_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproperties\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparameter\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPRECTOT\u001b[39m\u001b[38;5;124m'\u001b[39m][date],\n\u001b[1;32m     79\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwind_speed\u001b[39m\u001b[38;5;124m'\u001b[39m: weather_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproperties\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparameter\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWS10M\u001b[39m\u001b[38;5;124m'\u001b[39m][date],\n\u001b[1;32m     80\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msolar_radiation\u001b[39m\u001b[38;5;124m'\u001b[39m: weather_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproperties\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparameter\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mALLSKY_SFC_SW_DWN\u001b[39m\u001b[38;5;124m'\u001b[39m][date]\n\u001b[1;32m     81\u001b[0m                 })\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClimatic data saved to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'PRECTOT'"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import csv\n",
    "\n",
    "# NASA POWER API endpoint\n",
    "def get_nasa_power_data(lat, lon, start_date, end_date):\n",
    "    url = f\"https://power.larc.nasa.gov/api/temporal/daily/point?start={start_date}&end={end_date}&latitude={lat}&longitude={lon}&community=RE&parameters=T2M,PRECTOT,WS10M,ALLSKY_SFC_SW_DWN&format=JSON\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(f\"Error fetching data for {lat}, {lon}: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "# Coordinates for Nigerian states\n",
    "nigerian_states_coords = {\n",
    "    'Abia': {'lat': 5.4527, 'lon': 7.5248},\n",
    "    'Adamawa': {'lat': 9.3265, 'lon': 12.3984},\n",
    "    'Akwa Ibom': {'lat': 5.0370, 'lon': 7.9128},\n",
    "    'Anambra': {'lat': 6.2209, 'lon': 7.0676},\n",
    "    'Bauchi': {'lat': 10.3157, 'lon': 9.8442},\n",
    "    'Bayelsa': {'lat': 4.7719, 'lon': 6.0699},\n",
    "    'Benue': {'lat': 7.3369, 'lon': 8.7404},\n",
    "    'Borno': {'lat': 11.8333, 'lon': 13.1500},\n",
    "    'Cross River': {'lat': 5.9631, 'lon': 8.5367},\n",
    "    'Delta': {'lat': 5.8904, 'lon': 5.6800},\n",
    "    'Ebonyi': {'lat': 6.2649, 'lon': 8.0130},\n",
    "    'Edo': {'lat': 6.5244, 'lon': 5.5197},\n",
    "    'Ekiti': {'lat': 7.6233, 'lon': 5.2190},\n",
    "    'Enugu': {'lat': 6.5244, 'lon': 7.5176},\n",
    "    'Gombe': {'lat': 10.2900, 'lon': 11.1700},\n",
    "    'Imo': {'lat': 5.5720, 'lon': 7.0588},\n",
    "    'Jigawa': {'lat': 12.1356, 'lon': 9.9285},\n",
    "    'Kaduna': {'lat': 10.5105, 'lon': 7.4165},\n",
    "    'Kano': {'lat': 12.0022, 'lon': 8.5919},\n",
    "    'Katsina': {'lat': 12.9908, 'lon': 7.5970},\n",
    "    'Kebbi': {'lat': 12.4500, 'lon': 4.1994},\n",
    "    'Kogi': {'lat': 7.7969, 'lon': 6.7333},\n",
    "    'Kwara': {'lat': 8.9669, 'lon': 4.5624},\n",
    "    'Lagos': {'lat': 6.5244, 'lon': 3.3792},\n",
    "    'Nasarawa': {'lat': 8.5373, 'lon': 8.2000},\n",
    "    'Niger': {'lat': 9.0810, 'lon': 6.5212},\n",
    "    'Ogun': {'lat': 7.1609, 'lon': 3.3466},\n",
    "    'Ondo': {'lat': 7.2507, 'lon': 5.1931},\n",
    "    'Osun': {'lat': 7.5628, 'lon': 4.5192},\n",
    "    'Oyo': {'lat': 7.9467, 'lon': 3.4820},\n",
    "    'Plateau': {'lat': 9.2182, 'lon': 9.5175},\n",
    "    'Rivers': {'lat': 4.8156, 'lon': 7.0498},\n",
    "    'Sokoto': {'lat': 13.0059, 'lon': 5.2476},\n",
    "    'Taraba': {'lat': 8.8937, 'lon': 11.3598},\n",
    "    'Yobe': {'lat': 12.0015, 'lon': 11.5000},\n",
    "    'Zamfara': {'lat': 12.1717, 'lon': 6.6614}\n",
    "}\n",
    "\n",
    "# Dates for fetching data\n",
    "start_date = \"20180101\"\n",
    "end_date = \"20221231\"\n",
    "\n",
    "# File to save weather data\n",
    "output_file = 'nasa_power_climatic_data.csv'\n",
    "\n",
    "# Open CSV file and write headers\n",
    "with open(output_file, 'w', newline='') as csvfile:\n",
    "    fieldnames = ['state', 'date', 'temperature', 'precipitation', 'wind_speed', 'solar_radiation']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "\n",
    "    # Fetch data for each state\n",
    "    for state, coords in nigerian_states_coords.items():\n",
    "        lat = coords['lat']\n",
    "        lon = coords['lon']\n",
    "        weather_data = get_nasa_power_data(lat, lon, start_date, end_date)\n",
    "        if weather_data and 'properties' in weather_data:\n",
    "            for date, values in weather_data['properties']['parameter']['T2M'].items():\n",
    "                writer.writerow({\n",
    "                    'state': state,\n",
    "                    'date': date,\n",
    "                    'temperature': values,\n",
    "                    'precipitation': weather_data['properties']['parameter']['PRECTOT'][date],\n",
    "                    'wind_speed': weather_data['properties']['parameter']['WS10M'][date],\n",
    "                    'solar_radiation': weather_data['properties']['parameter']['ALLSKY_SFC_SW_DWN'][date]\n",
    "                })\n",
    "\n",
    "print(f\"Climatic data saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "111ea67e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Climatic data saved to nasa_power_climatic_data.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import csv\n",
    "\n",
    "# NASA POWER API endpoint\n",
    "def get_nasa_power_data(lat, lon, start_date, end_date):\n",
    "    url = f\"https://power.larc.nasa.gov/api/temporal/daily/point?start={start_date}&end={end_date}&latitude={lat}&longitude={lon}&community=RE&parameters=T2M,PRECTOT,WS10M,ALLSKY_SFC_SW_DWN&format=JSON\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(f\"Error fetching data for {lat}, {lon}: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "# Coordinates for Nigerian states\n",
    "nigerian_states_coords = {\n",
    "    'Abia': {'lat': 5.4527, 'lon': 7.5248},\n",
    "    'Adamawa': {'lat': 9.3265, 'lon': 12.3984},\n",
    "    'Akwa Ibom': {'lat': 5.0370, 'lon': 7.9128},\n",
    "    'Anambra': {'lat': 6.2209, 'lon': 7.0676},\n",
    "    'Bauchi': {'lat': 10.3157, 'lon': 9.8442},\n",
    "    'Bayelsa': {'lat': 4.7719, 'lon': 6.0699},\n",
    "    'Benue': {'lat': 7.3369, 'lon': 8.7404},\n",
    "    'Borno': {'lat': 11.8333, 'lon': 13.1500},\n",
    "    'Cross River': {'lat': 5.9631, 'lon': 8.5367},\n",
    "    'Delta': {'lat': 5.8904, 'lon': 5.6800},\n",
    "    'Ebonyi': {'lat': 6.2649, 'lon': 8.0130},\n",
    "    'Edo': {'lat': 6.5244, 'lon': 5.5197},\n",
    "    'Ekiti': {'lat': 7.6233, 'lon': 5.2190},\n",
    "    'Enugu': {'lat': 6.5244, 'lon': 7.5176},\n",
    "    'Gombe': {'lat': 10.2900, 'lon': 11.1700},\n",
    "    'Imo': {'lat': 5.5720, 'lon': 7.0588},\n",
    "    'Jigawa': {'lat': 12.1356, 'lon': 9.9285},\n",
    "    'Kaduna': {'lat': 10.5105, 'lon': 7.4165},\n",
    "    'Kano': {'lat': 12.0022, 'lon': 8.5919},\n",
    "    'Katsina': {'lat': 12.9908, 'lon': 7.5970},\n",
    "    'Kebbi': {'lat': 12.4500, 'lon': 4.1994},\n",
    "    'Kogi': {'lat': 7.7969, 'lon': 6.7333},\n",
    "    'Kwara': {'lat': 8.9669, 'lon': 4.5624},\n",
    "    'Lagos': {'lat': 6.5244, 'lon': 3.3792},\n",
    "    'Nasarawa': {'lat': 8.5373, 'lon': 8.2000},\n",
    "    'Niger': {'lat': 9.0810, 'lon': 6.5212},\n",
    "    'Ogun': {'lat': 7.1609, 'lon': 3.3466},\n",
    "    'Ondo': {'lat': 7.2507, 'lon': 5.1931},\n",
    "    'Osun': {'lat': 7.5628, 'lon': 4.5192},\n",
    "    'Oyo': {'lat': 7.9467, 'lon': 3.4820},\n",
    "    'Plateau': {'lat': 9.2182, 'lon': 9.5175},\n",
    "    'Rivers': {'lat': 4.8156, 'lon': 7.0498},\n",
    "    'Sokoto': {'lat': 13.0059, 'lon': 5.2476},\n",
    "    'Taraba': {'lat': 8.8937, 'lon': 11.3598},\n",
    "    'Yobe': {'lat': 12.0015, 'lon': 11.5000},\n",
    "    'Zamfara': {'lat': 12.1717, 'lon': 6.6614}\n",
    "}\n",
    "\n",
    "# Dates for fetching data\n",
    "start_date = \"20180101\"\n",
    "end_date = \"20221231\"\n",
    "\n",
    "# File to save weather data\n",
    "output_file = 'nasa_power_climatic_data.csv'\n",
    "\n",
    "# Open CSV file and write headers\n",
    "with open(output_file, 'w', newline='') as csvfile:\n",
    "    fieldnames = ['state', 'date', 'temperature', 'precipitation', 'wind_speed', 'solar_radiation']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "\n",
    "    # Fetch data for each state\n",
    "    for state, coords in nigerian_states_coords.items():\n",
    "        lat = coords['lat']\n",
    "        lon = coords['lon']\n",
    "        weather_data = get_nasa_power_data(lat, lon, start_date, end_date)\n",
    "        if weather_data and 'properties' in weather_data:\n",
    "            for date, values in weather_data['properties']['parameter']['T2M'].items():\n",
    "                # Use .get() to handle missing data with default values\n",
    "                writer.writerow({\n",
    "                    'state': state,\n",
    "                    'date': date,\n",
    "                    'temperature': values,\n",
    "                    'precipitation': weather_data['properties']['parameter'].get('PRECTOT', {}).get(date, 'N/A'),\n",
    "                    'wind_speed': weather_data['properties']['parameter'].get('WS10M', {}).get(date, 'N/A'),\n",
    "                    'solar_radiation': weather_data['properties']['parameter'].get('ALLSKY_SFC_SW_DWN', {}).get(date, 'N/A')\n",
    "                })\n",
    "\n",
    "print(f\"Climatic data saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1b18ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for 5.4527, 7.5248: 422\n",
      "Error fetching data for 9.3265, 12.3984: 422\n",
      "Extended climatic data saved to nasa_power_climatic_data_extended.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import csv\n",
    "\n",
    "# NASA POWER API endpoint\n",
    "def get_nasa_power_data(lat, lon, start_date, end_date):\n",
    "    url = f\"https://power.larc.nasa.gov/api/temporal/daily/point?start={start_date}&end={end_date}&latitude={lat}&longitude={lon}&community=RE&parameters=T2M,PRECTOT,WS10M,ALLSKY_SFC_SW_DWN,RH2M,PS,T2MDEW,TSOIL_0_10CM&format=JSON\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(f\"Error fetching data for {lat}, {lon}: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "# Coordinates for Nigerian states\n",
    "nigerian_states_coords = {\n",
    "    'Abia': {'lat': 5.4527, 'lon': 7.5248},\n",
    "    'Adamawa': {'lat': 9.3265, 'lon': 12.3984},\n",
    "    # Add more states...\n",
    "}\n",
    "\n",
    "# Dates for fetching data\n",
    "start_date = \"20180101\"\n",
    "end_date = \"20221231\"\n",
    "\n",
    "# File to save weather data\n",
    "output_file = 'nasa_power_climatic_data_extended.csv'\n",
    "\n",
    "# Open CSV file and write headers\n",
    "with open(output_file, 'w', newline='') as csvfile:\n",
    "    fieldnames = ['state', 'date', 'temperature', 'precipitation', 'wind_speed', 'solar_radiation', 'humidity', 'surface_pressure', 'dew_point', 'soil_moisture']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "\n",
    "    # Fetch data for each state\n",
    "    for state, coords in nigerian_states_coords.items():\n",
    "        lat = coords['lat']\n",
    "        lon = coords['lon']\n",
    "        weather_data = get_nasa_power_data(lat, lon, start_date, end_date)\n",
    "        if weather_data and 'properties' in weather_data:\n",
    "            for date, values in weather_data['properties']['parameter']['T2M'].items():\n",
    "                # Use .get() to handle missing data with default values\n",
    "                writer.writerow({\n",
    "                    'state': state,\n",
    "                    'date': date,\n",
    "                    'temperature': values,\n",
    "                    'precipitation': weather_data['properties']['parameter'].get('PRECTOT', {}).get(date, 'N/A'),\n",
    "                    'wind_speed': weather_data['properties']['parameter'].get('WS10M', {}).get(date, 'N/A'),\n",
    "                    'solar_radiation': weather_data['properties']['parameter'].get('ALLSKY_SFC_SW_DWN', {}).get(date, 'N/A'),\n",
    "                    'humidity': weather_data['properties']['parameter'].get('RH2M', {}).get(date, 'N/A'),\n",
    "                    'surface_pressure': weather_data['properties']['parameter'].get('PS', {}).get(date, 'N/A'),\n",
    "                    'dew_point': weather_data['properties']['parameter'].get('T2MDEW', {}).get(date, 'N/A'),\n",
    "                    'soil_moisture': weather_data['properties']['parameter'].get('TSOIL_0_10CM', {}).get(date, 'N/A')\n",
    "                })\n",
    "\n",
    "print(f\"Extended climatic data saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b5591af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extended climatic data saved to nasa_power_climatic_data_extended.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import csv\n",
    "\n",
    "# NASA POWER API endpoint\n",
    "def get_nasa_power_data(lat, lon, start_date, end_date):\n",
    "    url = f\"https://power.larc.nasa.gov/api/temporal/daily/point?start={start_date}&end={end_date}&latitude={lat}&longitude={lon}&community=RE&parameters=T2M,PRECTOT,WS10M,ALLSKY_SFC_SW_DWN&format=JSON\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(f\"Error fetching data for {lat}, {lon}: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "# Coordinates for Nigerian states\n",
    "nigerian_states_coords = {\n",
    "    'Abia': {'lat': 5.4527, 'lon': 7.5248},\n",
    "    'Adamawa': {'lat': 9.3265, 'lon': 12.3984},\n",
    "    'Akwa Ibom': {'lat': 5.0370, 'lon': 7.9128},\n",
    "    'Anambra': {'lat': 6.2209, 'lon': 7.0676},\n",
    "    'Bauchi': {'lat': 10.3157, 'lon': 9.8442},\n",
    "    'Bayelsa': {'lat': 4.7719, 'lon': 6.0699},\n",
    "    'Benue': {'lat': 7.3369, 'lon': 8.7404},\n",
    "    'Borno': {'lat': 11.8333, 'lon': 13.1500},\n",
    "    'Cross River': {'lat': 5.9631, 'lon': 8.5367},\n",
    "    'Delta': {'lat': 5.8904, 'lon': 5.6800},\n",
    "    'Ebonyi': {'lat': 6.2649, 'lon': 8.0130},\n",
    "    'Edo': {'lat': 6.5244, 'lon': 5.5197},\n",
    "    'Ekiti': {'lat': 7.6233, 'lon': 5.2190},\n",
    "    'Enugu': {'lat': 6.5244, 'lon': 7.5176},\n",
    "    'Gombe': {'lat': 10.2900, 'lon': 11.1700},\n",
    "    'Imo': {'lat': 5.5720, 'lon': 7.0588},\n",
    "    'Jigawa': {'lat': 12.1356, 'lon': 9.9285},\n",
    "    'Kaduna': {'lat': 10.5105, 'lon': 7.4165},\n",
    "    'Kano': {'lat': 12.0022, 'lon': 8.5919},\n",
    "    'Katsina': {'lat': 12.9908, 'lon': 7.5970},\n",
    "    'Kebbi': {'lat': 12.4500, 'lon': 4.1994},\n",
    "    'Kogi': {'lat': 7.7969, 'lon': 6.7333},\n",
    "    'Kwara': {'lat': 8.9669, 'lon': 4.5624},\n",
    "    'Lagos': {'lat': 6.5244, 'lon': 3.3792},\n",
    "    'Nasarawa': {'lat': 8.5373, 'lon': 8.2000},\n",
    "    'Niger': {'lat': 9.0810, 'lon': 6.5212},\n",
    "    'Ogun': {'lat': 7.1609, 'lon': 3.3466},\n",
    "    'Ondo': {'lat': 7.2507, 'lon': 5.1931},\n",
    "    'Osun': {'lat': 7.5628, 'lon': 4.5192},\n",
    "    'Oyo': {'lat': 7.9467, 'lon': 3.4820},\n",
    "    'Plateau': {'lat': 9.2182, 'lon': 9.5175},\n",
    "    'Rivers': {'lat': 4.8156, 'lon': 7.0498},\n",
    "    'Sokoto': {'lat': 13.0059, 'lon': 5.2476},\n",
    "    'Taraba': {'lat': 8.8937, 'lon': 11.3598},\n",
    "    'Yobe': {'lat': 12.0015, 'lon': 11.5000},\n",
    "    'Zamfara': {'lat': 12.1717, 'lon': 6.6614}\n",
    "}\n",
    "\n",
    "# Dates for fetching data\n",
    "start_date = \"20180101\"\n",
    "end_date = \"20221231\"\n",
    "\n",
    "# File to save weather data\n",
    "output_file = 'nasa_power_climatic_data_extended.csv'\n",
    "\n",
    "# Open CSV file and write headers\n",
    "with open(output_file, 'w', newline='') as csvfile:\n",
    "    fieldnames = ['state', 'date', 'temperature', 'precipitation', 'wind_speed', 'solar_radiation', 'humidity', 'surface_pressure', 'dew_point', 'soil_moisture']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "\n",
    "    # Fetch data for each state\n",
    "    for state, coords in nigerian_states_coords.items():\n",
    "        lat = coords['lat']\n",
    "        lon = coords['lon']\n",
    "        weather_data = get_nasa_power_data(lat, lon, start_date, end_date)\n",
    "        if weather_data and 'properties' in weather_data:\n",
    "            for date, values in weather_data['properties']['parameter']['T2M'].items():\n",
    "                # Use .get() to handle missing data with default values\n",
    "                writer.writerow({\n",
    "                    'state': state,\n",
    "                    'date': date,\n",
    "                    'temperature': values,\n",
    "                    'precipitation': weather_data['properties']['parameter'].get('PRECTOT', {}).get(date, 'N/A'),\n",
    "                    'wind_speed': weather_data['properties']['parameter'].get('WS10M', {}).get(date, 'N/A'),\n",
    "                    'solar_radiation': weather_data['properties']['parameter'].get('ALLSKY_SFC_SW_DWN', {}).get(date, 'N/A'),\n",
    "                    'humidity': weather_data['properties']['parameter'].get('RH2M', {}).get(date, 'N/A'),\n",
    "                    'surface_pressure': weather_data['properties']['parameter'].get('PS', {}).get(date, 'N/A'),\n",
    "                    'dew_point': weather_data['properties']['parameter'].get('T2MDEW', {}).get(date, 'N/A'),\n",
    "                    'soil_moisture': weather_data['properties']['parameter'].get('TSOIL_0_10CM', {}).get(date, 'N/A')\n",
    "                })\n",
    "\n",
    "print(f\"Extended climatic data saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21a32213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting cdsapi\n",
      "  Downloading cdsapi-0.7.3-py2.py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting cads-api-client>=1.3.2 (from cdsapi)\n",
      "  Downloading cads_api_client-1.3.2-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: requests>=2.5.0 in ./anaconda3/lib/python3.11/site-packages (from cdsapi) (2.31.0)\n",
      "Requirement already satisfied: tqdm in ./anaconda3/lib/python3.11/site-packages (from cdsapi) (4.65.0)\n",
      "Requirement already satisfied: attrs in ./anaconda3/lib/python3.11/site-packages (from cads-api-client>=1.3.2->cdsapi) (24.1.0)\n",
      "Collecting multiurl (from cads-api-client>=1.3.2->cdsapi)\n",
      "  Downloading multiurl-0.3.1.tar.gz (18 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in ./anaconda3/lib/python3.11/site-packages (from cads-api-client>=1.3.2->cdsapi) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./anaconda3/lib/python3.11/site-packages (from requests>=2.5.0->cdsapi) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./anaconda3/lib/python3.11/site-packages (from requests>=2.5.0->cdsapi) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./anaconda3/lib/python3.11/site-packages (from requests>=2.5.0->cdsapi) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./anaconda3/lib/python3.11/site-packages (from requests>=2.5.0->cdsapi) (2024.7.4)\n",
      "Requirement already satisfied: pytz in ./anaconda3/lib/python3.11/site-packages (from multiurl->cads-api-client>=1.3.2->cdsapi) (2022.7)\n",
      "Requirement already satisfied: python-dateutil in ./anaconda3/lib/python3.11/site-packages (from multiurl->cads-api-client>=1.3.2->cdsapi) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in ./anaconda3/lib/python3.11/site-packages (from python-dateutil->multiurl->cads-api-client>=1.3.2->cdsapi) (1.16.0)\n",
      "Downloading cdsapi-0.7.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading cads_api_client-1.3.2-py3-none-any.whl (21 kB)\n",
      "Building wheels for collected packages: multiurl\n",
      "  Building wheel for multiurl (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for multiurl: filename=multiurl-0.3.1-py3-none-any.whl size=21132 sha256=9e4244fd9148d1f42982c4113db09a848822c23ec8f500e267d2ce338d7d43b9\n",
      "  Stored in directory: /Users/m1/Library/Caches/pip/wheels/88/54/66/4e1d7b60e01b6f962672d16bc2227061edd0af136327d6f9e4\n",
      "Successfully built multiurl\n",
      "Installing collected packages: multiurl, cads-api-client, cdsapi\n",
      "Successfully installed cads-api-client-1.3.2 cdsapi-0.7.3 multiurl-0.3.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install cdsapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a41bfa5e",
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Missing/incomplete configuration file: /Users/m1/.cdsapirc",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcdsapi\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m c \u001b[38;5;241m=\u001b[39m cdsapi\u001b[38;5;241m.\u001b[39mClient()\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Retrieve ERA5 reanalysis data for a specific region and time period\u001b[39;00m\n\u001b[1;32m      6\u001b[0m c\u001b[38;5;241m.\u001b[39mretrieve(\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreanalysis-era5-single-levels\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      8\u001b[0m     {\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     23\u001b[0m     },\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput.nc\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/cdsapi/api.py:281\u001b[0m, in \u001b[0;36mClient.__new__\u001b[0;34m(cls, url, key, *args, **kwargs)\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__new__\u001b[39m(\u001b[38;5;28mcls\u001b[39m, url\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 281\u001b[0m     _, token, _ \u001b[38;5;241m=\u001b[39m get_url_key_verify(url, key, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    282\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m token:\n\u001b[1;32m    283\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__new__\u001b[39m(\u001b[38;5;28mcls\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/cdsapi/api.py:69\u001b[0m, in \u001b[0;36mget_url_key_verify\u001b[0;34m(url, key, verify)\u001b[0m\n\u001b[1;32m     66\u001b[0m             verify \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbool\u001b[39m(\u001b[38;5;28mint\u001b[39m(config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mverify\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m1\u001b[39m)))\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m url \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 69\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing/incomplete configuration file: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (dotrc))\n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m# If verify is still None, then we set to default value of True\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mException\u001b[0m: Missing/incomplete configuration file: /Users/m1/.cdsapirc"
     ]
    }
   ],
   "source": [
    "import cdsapi\n",
    "\n",
    "c = cdsapi.Client()\n",
    "\n",
    "# Retrieve ERA5 reanalysis data for a specific region and time period\n",
    "c.retrieve(\n",
    "    'reanalysis-era5-single-levels',\n",
    "    {\n",
    "        'product_type': 'reanalysis',\n",
    "        'variable': [\n",
    "            '2m_temperature', '2m_dewpoint_temperature', 'surface_pressure',\n",
    "            'total_precipitation', '10m_u_component_of_wind', '10m_v_component_of_wind',\n",
    "            'surface_solar_radiation_downwards', 'mean_sea_level_pressure',\n",
    "        ],\n",
    "        'year': ['2018', '2019', '2020', '2021', '2022'],\n",
    "        'month': ['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12'],\n",
    "        'day': ['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31'],\n",
    "        'time': ['00:00', '06:00', '12:00', '18:00'],\n",
    "        'format': 'netcdf',\n",
    "        'area': [\n",
    "            13.0, 3.0, 4.0, 14.0,  # Define your bounding box (N, W, S, E) for Nigeria\n",
    "        ],\n",
    "    },\n",
    "    'output.nc')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4ba5f3f",
   "metadata": {},
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "403 Client Error: Forbidden for url: https://cds-beta.climate.copernicus.eu/api/retrieve/v1/processes/reanalysis-era5-single-levels/execution\nrequired licences not accepted\nrequired licences not accepted; please accept the following licences to proceed: [{'id': 'licence-to-use-copernicus-products', 'revision': 12}]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m c \u001b[38;5;241m=\u001b[39m cdsapi\u001b[38;5;241m.\u001b[39mClient()\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Example: Retrieve ERA5 reanalysis data\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m c\u001b[38;5;241m.\u001b[39mretrieve(\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreanalysis-era5-single-levels\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      9\u001b[0m     {\n\u001b[1;32m     10\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproduct_type\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreanalysis\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     11\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvariable\u001b[39m\u001b[38;5;124m'\u001b[39m: [\n\u001b[1;32m     12\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2m_temperature\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurface_pressure\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotal_precipitation\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     13\u001b[0m         ],\n\u001b[1;32m     14\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124myear\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2020\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     15\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmonth\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m01\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     16\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mday\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m01\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     17\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m12:00\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     18\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mformat\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnetcdf\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     19\u001b[0m     },\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput.nc\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/cads_api_client/legacy_api_client.py:160\u001b[0m, in \u001b[0;36mLegacyApiClient.retrieve\u001b[0;34m(self, name, request, target)\u001b[0m\n\u001b[1;32m    158\u001b[0m submitted: processing\u001b[38;5;241m.\u001b[39mRemote \u001b[38;5;241m|\u001b[39m processing\u001b[38;5;241m.\u001b[39mResults\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwait_until_complete:\n\u001b[0;32m--> 160\u001b[0m     submitted \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogging_decorator(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39msubmit_and_wait_on_result)(\n\u001b[1;32m    161\u001b[0m         collection_id\u001b[38;5;241m=\u001b[39mname,\n\u001b[1;32m    162\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrequest,\n\u001b[1;32m    163\u001b[0m     )\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    165\u001b[0m     submitted \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogging_decorator(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39msubmit)(\n\u001b[1;32m    166\u001b[0m         collection_id\u001b[38;5;241m=\u001b[39mname,\n\u001b[1;32m    167\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrequest,\n\u001b[1;32m    168\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/cads_api_client/legacy_api_client.py:143\u001b[0m, in \u001b[0;36mLegacyApiClient.logging_decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m LoggingContext(\n\u001b[1;32m    141\u001b[0m         logger\u001b[38;5;241m=\u001b[39mprocessing\u001b[38;5;241m.\u001b[39mlogger, quiet\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquiet, debug\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_debug\n\u001b[1;32m    142\u001b[0m     ):\n\u001b[0;32m--> 143\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/cads_api_client/api_client.py:132\u001b[0m, in \u001b[0;36mApiClient.submit_and_wait_on_result\u001b[0;34m(self, collection_id, **request)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msubmit_and_wait_on_result\u001b[39m(\n\u001b[1;32m    130\u001b[0m     \u001b[38;5;28mself\u001b[39m, collection_id: \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrequest: Any\n\u001b[1;32m    131\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m processing\u001b[38;5;241m.\u001b[39mResults:\n\u001b[0;32m--> 132\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretrieve_api\u001b[38;5;241m.\u001b[39msubmit_and_wait_on_result(collection_id, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrequest)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/cads_api_client/processing.py:555\u001b[0m, in \u001b[0;36mProcessing.submit_and_wait_on_result\u001b[0;34m(self, collection_id, **request)\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msubmit_and_wait_on_result\u001b[39m(\u001b[38;5;28mself\u001b[39m, collection_id: \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrequest: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Results:\n\u001b[0;32m--> 555\u001b[0m     remote \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubmit(collection_id, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrequest)\n\u001b[1;32m    556\u001b[0m     remote\u001b[38;5;241m.\u001b[39mwait_on_result()\n\u001b[1;32m    557\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m remote\u001b[38;5;241m.\u001b[39mmake_results()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/cads_api_client/processing.py:551\u001b[0m, in \u001b[0;36mProcessing.submit\u001b[0;34m(self, collection_id, **request)\u001b[0m\n\u001b[1;32m    550\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msubmit\u001b[39m(\u001b[38;5;28mself\u001b[39m, collection_id: \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrequest: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Remote:\n\u001b[0;32m--> 551\u001b[0m     status_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_execute(collection_id, request)\n\u001b[1;32m    552\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m status_info\u001b[38;5;241m.\u001b[39mmake_remote()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/cads_api_client/processing.py:532\u001b[0m, in \u001b[0;36mProcessing.process_execute\u001b[0;34m(self, process_id, inputs)\u001b[0m\n\u001b[1;32m    526\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess_execute\u001b[39m(\n\u001b[1;32m    527\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    528\u001b[0m     process_id: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m    529\u001b[0m     inputs: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any],\n\u001b[1;32m    530\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m StatusInfo:\n\u001b[1;32m    531\u001b[0m     url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/processes/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprocess_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/execution\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m StatusInfo\u001b[38;5;241m.\u001b[39mfrom_request(\n\u001b[1;32m    533\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url, json\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: inputs}, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_kwargs\n\u001b[1;32m    534\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/cads_api_client/processing.py:133\u001b[0m, in \u001b[0;36mApiResponse.from_request\u001b[0;34m(cls, method, url, headers, session, retry_options, request_options, download_options, sleep_max, cleanup, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m response \u001b[38;5;241m=\u001b[39m robust_request(\n\u001b[1;32m    129\u001b[0m     method, url, headers\u001b[38;5;241m=\u001b[39mheaders, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrequest_options, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    130\u001b[0m )\n\u001b[1;32m    131\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mREPLY \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 133\u001b[0m cads_raise_for_status(response)\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(\n\u001b[1;32m    136\u001b[0m     response,\n\u001b[1;32m    137\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    143\u001b[0m     cleanup\u001b[38;5;241m=\u001b[39mcleanup,\n\u001b[1;32m    144\u001b[0m )\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog_messages()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/cads_api_client/processing.py:71\u001b[0m, in \u001b[0;36mcads_raise_for_status\u001b[0;34m(response)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m         message \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[1;32m     66\u001b[0m             [\n\u001b[1;32m     67\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Client Error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mreason\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for url: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     68\u001b[0m                 error_json_to_message(error_json),\n\u001b[1;32m     69\u001b[0m             ]\n\u001b[1;32m     70\u001b[0m         )\n\u001b[0;32m---> 71\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mHTTPError(message, response\u001b[38;5;241m=\u001b[39mresponse)\n\u001b[1;32m     72\u001b[0m response\u001b[38;5;241m.\u001b[39mraise_for_status()\n",
      "\u001b[0;31mHTTPError\u001b[0m: 403 Client Error: Forbidden for url: https://cds-beta.climate.copernicus.eu/api/retrieve/v1/processes/reanalysis-era5-single-levels/execution\nrequired licences not accepted\nrequired licences not accepted; please accept the following licences to proceed: [{'id': 'licence-to-use-copernicus-products', 'revision': 12}]"
     ]
    }
   ],
   "source": [
    "import cdsapi\n",
    "\n",
    "# Initialize the CDS API client\n",
    "c = cdsapi.Client()\n",
    "\n",
    "# Example: Retrieve ERA5 reanalysis data\n",
    "c.retrieve(\n",
    "    'reanalysis-era5-single-levels',\n",
    "    {\n",
    "        'product_type': 'reanalysis',\n",
    "        'variable': [\n",
    "            '2m_temperature', 'surface_pressure', 'total_precipitation',\n",
    "        ],\n",
    "        'year': '2020',\n",
    "        'month': '01',\n",
    "        'day': '01',\n",
    "        'time': '12:00',\n",
    "        'format': 'netcdf',\n",
    "    },\n",
    "    'output.nc')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5119d271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weather data saved to noaa_gsod_weather_data.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import csv\n",
    "\n",
    "# NOAA GSOD Data API endpoint\n",
    "base_url = \"https://www.ncei.noaa.gov/access/services/data/v1\"\n",
    "\n",
    "def get_noaa_data(station_id, start_date, end_date, dataset=\"daily-summaries\"):\n",
    "    params = {\n",
    "        'dataset': dataset,\n",
    "        'stations': station_id,\n",
    "        'startDate': start_date,\n",
    "        'endDate': end_date,\n",
    "        'format': 'csv'\n",
    "    }\n",
    "    response = requests.get(base_url, params=params)\n",
    "    if response.status_code == 200:\n",
    "        return response.content.decode('utf-8')\n",
    "    else:\n",
    "        print(f\"Error fetching data for {station_id}: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "# Example: Fetch data for a weather station in Lagos (use station ID from NCEI)\n",
    "station_id = \"65221099999\"  # Replace with actual station ID\n",
    "start_date = \"2018-01-01\"\n",
    "end_date = \"2022-12-31\"\n",
    "\n",
    "# Fetch data\n",
    "noaa_data = get_noaa_data(station_id, start_date, end_date)\n",
    "\n",
    "# Save to CSV file\n",
    "with open('noaa_gsod_weather_data.csv', 'w') as file:\n",
    "    file.write(noaa_data)\n",
    "\n",
    "print(\"Weather data saved to noaa_gsod_weather_data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9586950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for Abia...\n",
      "Fetching data for Adamawa...\n",
      "Fetching data for Akwa Ibom...\n",
      "Fetching data for Anambra...\n",
      "Fetching data for Bauchi...\n",
      "Fetching data for Bayelsa...\n",
      "Fetching data for Benue...\n",
      "Fetching data for Borno...\n",
      "Fetching data for Cross River...\n",
      "Fetching data for Delta...\n",
      "Fetching data for Ebonyi...\n",
      "Fetching data for Edo...\n",
      "Fetching data for Ekiti...\n",
      "Fetching data for Enugu...\n",
      "Fetching data for Gombe...\n",
      "Fetching data for Imo...\n",
      "Fetching data for Jigawa...\n",
      "Fetching data for Kaduna...\n",
      "Fetching data for Kano...\n",
      "Fetching data for Katsina...\n",
      "Fetching data for Kebbi...\n",
      "Fetching data for Kogi...\n",
      "Fetching data for Kwara...\n",
      "Fetching data for Lagos...\n",
      "Fetching data for Nasarawa...\n",
      "Fetching data for Niger...\n",
      "Fetching data for Ogun...\n",
      "Fetching data for Ondo...\n",
      "Fetching data for Osun...\n",
      "Fetching data for Oyo...\n",
      "Fetching data for Plateau...\n",
      "Fetching data for Rivers...\n",
      "Fetching data for Sokoto...\n",
      "Fetching data for Taraba...\n",
      "Fetching data for Yobe...\n",
      "Fetching data for Zamfara...\n",
      "Comprehensive weather data saved to noaa_nigeria_weather_data_comprehensive.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import csv\n",
    "\n",
    "# NOAA GSOD Data API endpoint\n",
    "base_url = \"https://www.ncei.noaa.gov/access/services/data/v1\"\n",
    "\n",
    "def get_noaa_data(station_id, start_date, end_date, dataset=\"daily-summaries\"):\n",
    "    params = {\n",
    "        'dataset': dataset,\n",
    "        'stations': station_id,\n",
    "        'startDate': start_date,\n",
    "        'endDate': end_date,\n",
    "        'format': 'csv'\n",
    "    }\n",
    "    response = requests.get(base_url, params=params)\n",
    "    if response.status_code == 200:\n",
    "        return response.content.decode('utf-8')\n",
    "    else:\n",
    "        print(f\"Error fetching data for {station_id}: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "# List of station IDs for Nigerian states\n",
    "nigerian_station_ids = {\n",
    "    'Abia': '65232099999',\n",
    "    'Adamawa': '65225099999',\n",
    "    'Akwa Ibom': '65212099999',\n",
    "    'Anambra': '65227099999',\n",
    "    'Bauchi': '65132099999',\n",
    "    'Bayelsa': '65235099999',\n",
    "    'Benue': '65206099999',\n",
    "    'Borno': '65053099999',\n",
    "    'Cross River': '65201099999',\n",
    "    'Delta': '65230099999',\n",
    "    'Ebonyi': '65229099999',\n",
    "    'Edo': '65226099999',\n",
    "    'Ekiti': '65222099999',\n",
    "    'Enugu': '65230099999',\n",
    "    'Gombe': '65214099999',\n",
    "    'Imo': '65223099999',\n",
    "    'Jigawa': '65224099999',\n",
    "    'Kaduna': '65042099999',\n",
    "    'Kano': '65046099999',\n",
    "    'Katsina': '65041099999',\n",
    "    'Kebbi': '65225099999',\n",
    "    'Kogi': '65211099999',\n",
    "    'Kwara': '65208099999',\n",
    "    'Lagos': '65221099999',\n",
    "    'Nasarawa': '65218099999',\n",
    "    'Niger': '65207099999',\n",
    "    'Ogun': '65220099999',\n",
    "    'Ondo': '65215099999',\n",
    "    'Osun': '65204099999',\n",
    "    'Oyo': '65209099999',\n",
    "    'Plateau': '65110099999',\n",
    "    'Rivers': '65201099999',\n",
    "    'Sokoto': '65011099999',\n",
    "    'Taraba': '65226099999',\n",
    "    'Yobe': '65217099999',\n",
    "    'Zamfara': '65219099999'\n",
    "}\n",
    "\n",
    "# Set the date range for the data you want to fetch\n",
    "start_date = \"2018-01-01\"\n",
    "end_date = \"2022-12-31\"\n",
    "\n",
    "# Open a CSV file to save the data\n",
    "with open('noaa_nigeria_weather_data_comprehensive.csv', 'w', newline='') as csvfile:\n",
    "    fieldnames = ['station', 'date', 'temperature', 'dew_point', 'sea_level_pressure',\n",
    "                  'station_pressure', 'visibility', 'wind_speed', 'max_wind_speed',\n",
    "                  'max_gust', 'precipitation', 'snow_depth', 'weather_conditions']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "\n",
    "    # Loop through each station and fetch data\n",
    "    for state, station_id in nigerian_station_ids.items():\n",
    "        print(f\"Fetching data for {state}...\")\n",
    "        noaa_data = get_noaa_data(station_id, start_date, end_date)\n",
    "        if noaa_data:\n",
    "            # Write the fetched data to the CSV file\n",
    "            reader = csv.DictReader(noaa_data.splitlines())\n",
    "            for row in reader:\n",
    "                writer.writerow({\n",
    "                    'station': state,\n",
    "                    'date': row['DATE'],\n",
    "                    'temperature': row.get('TEMP', 'N/A'),\n",
    "                    'dew_point': row.get('DEWP', 'N/A'),\n",
    "                    'sea_level_pressure': row.get('SLP', 'N/A'),\n",
    "                    'station_pressure': row.get('STP', 'N/A'),\n",
    "                    'visibility': row.get('VISIB', 'N/A'),\n",
    "                    'wind_speed': row.get('WDSP', 'N/A'),\n",
    "                    'max_wind_speed': row.get('MXSPD', 'N/A'),\n",
    "                    'max_gust': row.get('GUST', 'N/A'),\n",
    "                    'precipitation': row.get('PRCP', 'N/A'),\n",
    "                    'snow_depth': row.get('SNDP', 'N/A'),\n",
    "                    'weather_conditions': row.get('FRSHTT', 'N/A')\n",
    "                })\n",
    "\n",
    "print(\"Comprehensive weather data saved to noaa_nigeria_weather_data_comprehensive.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9445124d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_noaa_data(station_id, start_date, end_date, dataset=\"daily-summaries\"):\n",
    "    params = {\n",
    "        'dataset': dataset,\n",
    "        'stations': station_id,\n",
    "        'startDate': start_date,\n",
    "        'endDate': end_date,\n",
    "        'format': 'csv'\n",
    "    }\n",
    "    response = requests.get(base_url, params=params)\n",
    "    if response.status_code == 200:\n",
    "        print(f\"Data for station {station_id}:\\n{response.text[:500]}...\\n\")  # Print first 500 characters for preview\n",
    "        return response.content.decode('utf-8')\n",
    "    else:\n",
    "        print(f\"Error fetching data for {station_id}: {response.status_code}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0677b81",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nigerian_station_ids' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m state, station_id \u001b[38;5;129;01min\u001b[39;00m nigerian_station_ids\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFetching data for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m     noaa_data \u001b[38;5;241m=\u001b[39m get_noaa_data(station_id, start_date, end_date)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nigerian_station_ids' is not defined"
     ]
    }
   ],
   "source": [
    "for state, station_id in nigerian_station_ids.items():\n",
    "    print(f\"Fetching data for {state}...\")\n",
    "    noaa_data = get_noaa_data(station_id, start_date, end_date)\n",
    "    if noaa_data:\n",
    "        reader = csv.DictReader(noaa_data.splitlines())\n",
    "        if reader.fieldnames:  # Check if fieldnames exist, meaning there is data\n",
    "            for row in reader:\n",
    "                writer.writerow({\n",
    "                    'station': state,\n",
    "                    'date': row.get('DATE', 'N/A'),\n",
    "                    'temperature': row.get('TEMP', 'N/A'),\n",
    "                    'dew_point': row.get('DEWP', 'N/A'),\n",
    "                    'sea_level_pressure': row.get('SLP', 'N/A'),\n",
    "                    'station_pressure': row.get('STP', 'N/A'),\n",
    "                    'visibility': row.get('VISIB', 'N/A'),\n",
    "                    'wind_speed': row.get('WDSP', 'N/A'),\n",
    "                    'max_wind_speed': row.get('MXSPD', 'N/A'),\n",
    "                    'max_gust': row.get('GUST', 'N/A'),\n",
    "                    'precipitation': row.get('PRCP', 'N/A'),\n",
    "                    'snow_depth': row.get('SNDP', 'N/A'),\n",
    "                    'weather_conditions': row.get('FRSHTT', 'N/A')\n",
    "                })\n",
    "        else:\n",
    "            print(f\"No data available for {state} (Station ID: {station_id}).\")\n",
    "    else:\n",
    "        print(f\"Skipping {state} due to data retrieval issues.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb7cca5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
